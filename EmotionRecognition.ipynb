{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimantAnalyse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH0i_jVS_8vp",
        "colab_type": "code",
        "outputId": "87c2f6cf-36ae-4f2c-efff-0eeb30b5c313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYe1v7EhjR7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "max_pad_len = 174\n",
        "\n",
        "def extract_features(file_name):\n",
        "  try:\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error encountered while parsing file: \", file_name)                                                                                                                                                                                           \n",
        "    return None \n",
        "     \n",
        "  return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzvoIifVkLCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load various imports \n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "train_path = 'drive/My Drive/Publics_datasets/Train/'\n",
        "file_path  = 'drive/My Drive/Colab Notebooks/Hack_datasets/train_label.csv'\n",
        "features = []\n",
        "file_no_decod = []\n",
        "\n",
        "# Iterate through each sound file and extract the features \n",
        "ffile = open(file_path, \"r\")\n",
        "#lines = ffile.readlines()\n",
        "lines = ffile.readlines()[1:]\n",
        "ffile.close()\n",
        "#print(len(lines))\n",
        "#next(lines)\n",
        "for line in lines:\n",
        "  lst_split = line.rstrip().split(',') #line.split(',')\n",
        "  file_name = lst_split[0]\n",
        "  class_label = lst_split[1]\n",
        "\n",
        "  file_name = train_path+file_name\n",
        "  data = extract_features(file_name)\n",
        "  if data is None:\n",
        "    file_no_decod.append(file_name)\n",
        "  else:\n",
        "    features.append([data, class_label])\n",
        "  #features.append([data, class_label])\n",
        "\n",
        "# Convert into a Panda dataframe \n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files')\n",
        "\n",
        "featuresdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw79kEeqm_MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dump function\n",
        "import pickle\n",
        "with open('drive/My Drive/Colab Notebooks/Hack_datasets/featuresdf_train.pd', 'wb') as handle:\n",
        "    pickle.dump(featuresdf, handle)\n",
        "featuresdf.to_csv('drive/My Drive/Colab Notebooks/Hack_datasets/featuresdf_train.csv')\n",
        "with open('drive/My Drive/Colab Notebooks/Hack_datasets/features_train_decode.pd', 'wb') as handle:\n",
        "    pickle.dump(file_no_decod, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEFX1ySJD6E",
        "colab_type": "code",
        "outputId": "bef5582e-dbab-4971-d950-1bedd01584af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "# Load various imports \n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import glob\n",
        "\n",
        "test_path = 'drive/My Drive/Publics_datasets/Public_Test/'\n",
        "features_testdf = []\n",
        "file_no_decod = []\n",
        "\n",
        "for file in glob.glob(test_path+\"/*.wav\"):\n",
        "#for file in glob.glob(\"sample_data/*.csv\"):\n",
        "  #file = file.rstrip()\n",
        "  basename = os.path.basename(file)\n",
        "  #print(file)\n",
        "  #print(basename)\n",
        "  #basename = basename.rstrip()#.split(',')\n",
        "  data = extract_features(file)\n",
        "  if data is None:\n",
        "    file_no_decod.append(basename)\n",
        "  else:\n",
        "    features_testdf.append([data, basename])\n",
        "  #features.append([data, class_label])\n",
        "\n",
        "# Convert into a Panda dataframe \n",
        "features_testdf = pd.DataFrame(features_testdf, columns=['feature','file_name'])\n",
        "\n",
        "print('Finished feature extraction from ', len(features_testdf), ' files')\n",
        "\n",
        "features_testdf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-001507.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000269.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000168.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000184.wav\n",
            "Finished feature extraction from  1102  files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-447.41431816688515, -446.7360781220712, -44...</td>\n",
              "      <td>PAEP-000601.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-470.43278021186745, -467.84069614053965, -4...</td>\n",
              "      <td>PAEP-000602.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-450.8596692386287, -441.6545815221217, -442...</td>\n",
              "      <td>PAEP-000599.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-464.1534008319131, -461.67987338395085, -46...</td>\n",
              "      <td>PAEP-000598.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-412.491410614026, -422.27315006923163, -441...</td>\n",
              "      <td>PAEP-000608.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature        file_name\n",
              "0  [[-447.41431816688515, -446.7360781220712, -44...  PAEP-000601.wav\n",
              "1  [[-470.43278021186745, -467.84069614053965, -4...  PAEP-000602.wav\n",
              "2  [[-450.8596692386287, -441.6545815221217, -442...  PAEP-000599.wav\n",
              "3  [[-464.1534008319131, -461.67987338395085, -46...  PAEP-000598.wav\n",
              "4  [[-412.491410614026, -422.27315006923163, -441...  PAEP-000608.wav"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKsWSXEQSz2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dump function\n",
        "import pickle\n",
        "with open('drive/My Drive/Colab Notebooks/Hack_datasets/featuresdf_test.pd', 'wb') as handle:\n",
        "    pickle.dump(features_testdf, handle)\n",
        "features_testdf.to_csv('drive/My Drive/Colab Notebooks/Hack_datasets/featuresdf_test.csv')\n",
        "with open('drive/My Drive/Colab Notebooks/Hack_datasets/features_test_decode.pd', 'wb') as handle:\n",
        "    pickle.dump(file_no_decod, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbpsY8kuRDzW",
        "colab_type": "code",
        "outputId": "4f05f1b3-58bf-4882-e2ce-757b26f12c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "features_testdf2 = []\n",
        "file_no_decod2 = []\n",
        "for x_file in file_no_decod:\n",
        "  #print(test_path+x_file)\n",
        "  data = extract_features(test_path+x_file)\n",
        "  if data is None:\n",
        "    file_no_decod2.append(basename)\n",
        "  else:\n",
        "    features_testdf2.append([data, basename])\n",
        "\n",
        "len(features_testdf2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-001507.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000269.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000168.wav\n",
            "Error encountered while parsing file:  drive/My Drive/Publics_datasets/Public_Test/PAEP-000184.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn87aP5GA1K8",
        "colab_type": "code",
        "outputId": "b6bd27d8-7ab4-4977-e48f-43a69a4f7134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "#Load Datasets\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "with open('drive/My Drive/Colab Notebooks/Hack_datasets/featuresdf_train.pd', 'rb') as handle:\n",
        "    featuresdf = pickle.load(handle)\n",
        "\n",
        "print(featuresdf.shape)\n",
        "featuresdf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5170, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-619.3343721905136, -545.3813821723509, -492...</td>\n",
              "      <td>3\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-494.21440239103555, -493.90385568196444, -4...</td>\n",
              "      <td>5\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-475.7970468784426, -475.0189023387284, -474...</td>\n",
              "      <td>4\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-460.9420217646069, -461.082112830963, -453....</td>\n",
              "      <td>1\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-475.22898308480717, -472.7163584593154, -47...</td>\n",
              "      <td>0\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature class_label\n",
              "0  [[-619.3343721905136, -545.3813821723509, -492...         3\\n\n",
              "1  [[-494.21440239103555, -493.90385568196444, -4...         5\\n\n",
              "2  [[-475.7970468784426, -475.0189023387284, -474...         4\\n\n",
              "3  [[-460.9420217646069, -461.082112830963, -453....         1\\n\n",
              "4  [[-475.22898308480717, -472.7163584593154, -47...         0\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMiDgOuVAAtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "\n",
        "# split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NRrbJ1lAKUZ",
        "colab_type": "code",
        "outputId": "ad4be382-d686-477e-d4d3-3da30f2bd691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4136, 40, 174)\n",
            "(1034, 40, 174)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or8hS1t4BHhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "num_rows = 40\n",
        "num_columns = 174\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbUINrx7P9CJ",
        "colab_type": "code",
        "outputId": "21c7b231-0175-4e73-c2ed-b2b0cd022684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Construct model \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmcDkxppUyE5",
        "colab_type": "code",
        "outputId": "b31705e9-b11a-4990-b7ce-c74950bdd629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOdIoyPtbAtt",
        "colab_type": "code",
        "outputId": "1bc7f22c-8155-45d8-88d9-42453cb85441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        }
      },
      "source": [
        "# Display model architecture summary \n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 39, 173, 16)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 19, 86, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 19, 86, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 18, 85, 32)        2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 41, 64)         8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 20, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 20, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 19, 128)        32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 44,086\n",
            "Trainable params: 44,086\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1034/1034 [==============================] - 7s 7ms/step\n",
            "Pre-training accuracy: 16.3443%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_nuDSC0BQRk",
        "colab_type": "code",
        "outputId": "b5d6a792-becd-4f10-b4f7-45c803e27ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "\n",
        "#num_epochs = 12\n",
        "#num_batch_size = 128\n",
        "\n",
        "num_epochs = 700\n",
        "num_batch_size = 64\n",
        "\n",
        "file_path_mod  = 'drive/My Drive/Colab Notebooks/Hack_datasets/'\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=file_path_mod+'saved_models/weights.best.basic_cnn3.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4136 samples, validate on 1034 samples\n",
            "Epoch 1/700\n",
            "4136/4136 [==============================] - 2s 570us/step - loss: 3.3751 - acc: 0.2198 - val_loss: 1.6976 - val_acc: 0.3017\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.69765, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 2/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.6684 - acc: 0.2930 - val_loss: 1.6092 - val_acc: 0.3085\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.69765 to 1.60917, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 3/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.5980 - acc: 0.3315 - val_loss: 1.5763 - val_acc: 0.3172\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.60917 to 1.57629, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 4/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.5509 - acc: 0.3431 - val_loss: 1.5404 - val_acc: 0.3704\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.57629 to 1.54040, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 5/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.5250 - acc: 0.3574 - val_loss: 1.5143 - val_acc: 0.3820\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.54040 to 1.51434, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 6/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 1.5218 - acc: 0.3622 - val_loss: 1.5143 - val_acc: 0.3772\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.51434 to 1.51433, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 7/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.4818 - acc: 0.3760 - val_loss: 1.4521 - val_acc: 0.4313\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.51433 to 1.45207, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 8/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.4555 - acc: 0.4059 - val_loss: 1.4240 - val_acc: 0.4526\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.45207 to 1.42400, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 9/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.4355 - acc: 0.4038 - val_loss: 1.4165 - val_acc: 0.4284\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.42400 to 1.41649, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 10/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.4145 - acc: 0.4209 - val_loss: 1.3966 - val_acc: 0.4449\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.41649 to 1.39656, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 11/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.3977 - acc: 0.4209 - val_loss: 1.3533 - val_acc: 0.4720\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.39656 to 1.35327, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 12/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.3949 - acc: 0.4367 - val_loss: 1.3751 - val_acc: 0.4865\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.35327\n",
            "Epoch 13/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.3673 - acc: 0.4381 - val_loss: 1.3454 - val_acc: 0.4720\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.35327 to 1.34544, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 14/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.3648 - acc: 0.4536 - val_loss: 1.3248 - val_acc: 0.4797\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.34544 to 1.32476, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 15/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.3481 - acc: 0.4594 - val_loss: 1.3245 - val_acc: 0.5058\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.32476 to 1.32452, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 16/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.3472 - acc: 0.4562 - val_loss: 1.3441 - val_acc: 0.4565\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.32452\n",
            "Epoch 17/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.3200 - acc: 0.4705 - val_loss: 1.3034 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.32452 to 1.30345, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 18/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.3080 - acc: 0.4768 - val_loss: 1.2970 - val_acc: 0.4932\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.30345 to 1.29704, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 19/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.3251 - acc: 0.4681 - val_loss: 1.2907 - val_acc: 0.5068\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.29704 to 1.29072, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 20/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.3007 - acc: 0.4794 - val_loss: 1.2702 - val_acc: 0.5174\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.29072 to 1.27019, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 21/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.2922 - acc: 0.4804 - val_loss: 1.2566 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.27019 to 1.25664, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 22/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.2841 - acc: 0.4872 - val_loss: 1.2988 - val_acc: 0.4836\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.25664\n",
            "Epoch 23/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.2830 - acc: 0.4915 - val_loss: 1.2618 - val_acc: 0.5106\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.25664\n",
            "Epoch 24/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2622 - acc: 0.4959 - val_loss: 1.2283 - val_acc: 0.5348\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.25664 to 1.22825, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 25/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2689 - acc: 0.5015 - val_loss: 1.2472 - val_acc: 0.5126\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.22825\n",
            "Epoch 26/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.2632 - acc: 0.4944 - val_loss: 1.2706 - val_acc: 0.5029\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.22825\n",
            "Epoch 27/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.2542 - acc: 0.5034 - val_loss: 1.2462 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.22825\n",
            "Epoch 28/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.2456 - acc: 0.5123 - val_loss: 1.2026 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.22825 to 1.20258, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 29/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.2322 - acc: 0.5135 - val_loss: 1.2016 - val_acc: 0.5464\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.20258 to 1.20165, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 30/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.2308 - acc: 0.5063 - val_loss: 1.2317 - val_acc: 0.5087\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.20165\n",
            "Epoch 31/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2294 - acc: 0.5005 - val_loss: 1.1815 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.20165 to 1.18152, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 32/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2289 - acc: 0.5176 - val_loss: 1.1908 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.18152\n",
            "Epoch 33/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2041 - acc: 0.5210 - val_loss: 1.1920 - val_acc: 0.5406\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.18152\n",
            "Epoch 34/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2092 - acc: 0.5259 - val_loss: 1.2008 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.18152\n",
            "Epoch 35/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.2040 - acc: 0.5343 - val_loss: 1.1916 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.18152\n",
            "Epoch 36/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.1898 - acc: 0.5302 - val_loss: 1.2003 - val_acc: 0.5368\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.18152\n",
            "Epoch 37/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.2028 - acc: 0.5251 - val_loss: 1.1853 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.18152\n",
            "Epoch 38/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.1914 - acc: 0.5377 - val_loss: 1.1695 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.18152 to 1.16954, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 39/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.1826 - acc: 0.5348 - val_loss: 1.1794 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.16954\n",
            "Epoch 40/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.1710 - acc: 0.5389 - val_loss: 1.1712 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.16954\n",
            "Epoch 41/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.1725 - acc: 0.5358 - val_loss: 1.1389 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.16954 to 1.13891, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 42/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.1674 - acc: 0.5455 - val_loss: 1.1402 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.13891\n",
            "Epoch 43/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 1.1648 - acc: 0.5416 - val_loss: 1.1389 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.13891 to 1.13887, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 44/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.1473 - acc: 0.5561 - val_loss: 1.1425 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.13887\n",
            "Epoch 45/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.1473 - acc: 0.5525 - val_loss: 1.1236 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.13887 to 1.12359, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 46/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 1.1512 - acc: 0.5510 - val_loss: 1.0983 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.12359 to 1.09829, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 47/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.1503 - acc: 0.5503 - val_loss: 1.1225 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09829\n",
            "Epoch 48/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.1572 - acc: 0.5539 - val_loss: 1.1069 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09829\n",
            "Epoch 49/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.1442 - acc: 0.5595 - val_loss: 1.1314 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.09829\n",
            "Epoch 50/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.1256 - acc: 0.5638 - val_loss: 1.1009 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09829\n",
            "Epoch 51/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.1136 - acc: 0.5783 - val_loss: 1.1164 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.09829\n",
            "Epoch 52/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.1007 - acc: 0.5844 - val_loss: 1.0857 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00052: val_loss improved from 1.09829 to 1.08567, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 53/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.1097 - acc: 0.5675 - val_loss: 1.1220 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.08567\n",
            "Epoch 54/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.1111 - acc: 0.5633 - val_loss: 1.0764 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00054: val_loss improved from 1.08567 to 1.07638, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 55/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.1015 - acc: 0.5793 - val_loss: 1.0766 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.07638\n",
            "Epoch 56/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.0942 - acc: 0.5853 - val_loss: 1.0698 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00056: val_loss improved from 1.07638 to 1.06979, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 57/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0915 - acc: 0.5754 - val_loss: 1.0669 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00057: val_loss improved from 1.06979 to 1.06695, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 58/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.0845 - acc: 0.5914 - val_loss: 1.0799 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.06695\n",
            "Epoch 59/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 1.0929 - acc: 0.5866 - val_loss: 1.0719 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.06695\n",
            "Epoch 60/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.0835 - acc: 0.5820 - val_loss: 1.0555 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00060: val_loss improved from 1.06695 to 1.05550, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 61/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 1.0600 - acc: 0.5962 - val_loss: 1.0514 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00061: val_loss improved from 1.05550 to 1.05139, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 62/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0825 - acc: 0.5846 - val_loss: 1.0527 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.05139\n",
            "Epoch 63/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0738 - acc: 0.5803 - val_loss: 1.0822 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.05139\n",
            "Epoch 64/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 1.0531 - acc: 0.5933 - val_loss: 1.0595 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.05139\n",
            "Epoch 65/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 1.0472 - acc: 0.6015 - val_loss: 1.0595 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.05139\n",
            "Epoch 66/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.0422 - acc: 0.5967 - val_loss: 1.0170 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00066: val_loss improved from 1.05139 to 1.01700, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 67/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.0449 - acc: 0.5948 - val_loss: 1.0484 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.01700\n",
            "Epoch 68/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0432 - acc: 0.5948 - val_loss: 1.0751 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.01700\n",
            "Epoch 69/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0259 - acc: 0.6124 - val_loss: 1.0686 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.01700\n",
            "Epoch 70/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.0253 - acc: 0.6054 - val_loss: 1.0592 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.01700\n",
            "Epoch 71/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 1.0259 - acc: 0.6047 - val_loss: 1.0555 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.01700\n",
            "Epoch 72/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 1.0279 - acc: 0.6095 - val_loss: 1.0308 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.01700\n",
            "Epoch 73/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.0132 - acc: 0.6153 - val_loss: 1.0326 - val_acc: 0.6151\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.01700\n",
            "Epoch 74/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 1.0331 - acc: 0.6020 - val_loss: 1.0361 - val_acc: 0.6219\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.01700\n",
            "Epoch 75/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.9896 - acc: 0.6274 - val_loss: 1.0131 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00075: val_loss improved from 1.01700 to 1.01308, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 76/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 1.0053 - acc: 0.6146 - val_loss: 1.0076 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00076: val_loss improved from 1.01308 to 1.00764, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 77/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.9970 - acc: 0.6240 - val_loss: 1.0390 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.00764\n",
            "Epoch 78/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.9842 - acc: 0.6313 - val_loss: 1.0015 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00078: val_loss improved from 1.00764 to 1.00154, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 79/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.9903 - acc: 0.6262 - val_loss: 1.0590 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.00154\n",
            "Epoch 80/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.9929 - acc: 0.6231 - val_loss: 1.0100 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.00154\n",
            "Epoch 81/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.9861 - acc: 0.6274 - val_loss: 1.0145 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.00154\n",
            "Epoch 82/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.9796 - acc: 0.6235 - val_loss: 1.0163 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.00154\n",
            "Epoch 83/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.9544 - acc: 0.6410 - val_loss: 1.0046 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.00154\n",
            "Epoch 84/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.9448 - acc: 0.6482 - val_loss: 1.0081 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.00154\n",
            "Epoch 85/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.9659 - acc: 0.6325 - val_loss: 1.0150 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.00154\n",
            "Epoch 86/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.9522 - acc: 0.6366 - val_loss: 0.9815 - val_acc: 0.6354\n",
            "\n",
            "Epoch 00086: val_loss improved from 1.00154 to 0.98151, saving model to drive/My Drive/Colab Notebooks/Hack_datasets/saved_models/weights.best.basic_cnn3.hdf5\n",
            "Epoch 87/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.9662 - acc: 0.6320 - val_loss: 1.0183 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.98151\n",
            "Epoch 88/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.9281 - acc: 0.6521 - val_loss: 1.0247 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.98151\n",
            "Epoch 89/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.9412 - acc: 0.6364 - val_loss: 1.0156 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.98151\n",
            "Epoch 90/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.9195 - acc: 0.6511 - val_loss: 1.0489 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.98151\n",
            "Epoch 91/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.9352 - acc: 0.6465 - val_loss: 1.0264 - val_acc: 0.6054\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.98151\n",
            "Epoch 92/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.9197 - acc: 0.6543 - val_loss: 0.9924 - val_acc: 0.6238\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.98151\n",
            "Epoch 93/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.9275 - acc: 0.6458 - val_loss: 1.0532 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.98151\n",
            "Epoch 94/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.9244 - acc: 0.6559 - val_loss: 1.0120 - val_acc: 0.6180\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.98151\n",
            "Epoch 95/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.9081 - acc: 0.6456 - val_loss: 1.0295 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.98151\n",
            "Epoch 96/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.9183 - acc: 0.6521 - val_loss: 1.0271 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.98151\n",
            "Epoch 97/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.9038 - acc: 0.6530 - val_loss: 0.9998 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.98151\n",
            "Epoch 98/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.9068 - acc: 0.6562 - val_loss: 1.0001 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.98151\n",
            "Epoch 99/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.8972 - acc: 0.6608 - val_loss: 0.9864 - val_acc: 0.6267\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.98151\n",
            "Epoch 100/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.8881 - acc: 0.6596 - val_loss: 0.9922 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.98151\n",
            "Epoch 101/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.8968 - acc: 0.6634 - val_loss: 1.0169 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.98151\n",
            "Epoch 102/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.8860 - acc: 0.6676 - val_loss: 0.9836 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.98151\n",
            "Epoch 103/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.8861 - acc: 0.6712 - val_loss: 1.0294 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.98151\n",
            "Epoch 104/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.8835 - acc: 0.6659 - val_loss: 1.0066 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.98151\n",
            "Epoch 105/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.8642 - acc: 0.6789 - val_loss: 0.9878 - val_acc: 0.6238\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.98151\n",
            "Epoch 106/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8921 - acc: 0.6714 - val_loss: 1.0318 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.98151\n",
            "Epoch 107/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.8786 - acc: 0.6632 - val_loss: 0.9986 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.98151\n",
            "Epoch 108/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.8711 - acc: 0.6796 - val_loss: 1.0201 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.98151\n",
            "Epoch 109/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.8569 - acc: 0.6721 - val_loss: 1.0020 - val_acc: 0.6248\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.98151\n",
            "Epoch 110/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.8430 - acc: 0.6886 - val_loss: 1.0145 - val_acc: 0.6238\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.98151\n",
            "Epoch 111/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8299 - acc: 0.6968 - val_loss: 1.0314 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.98151\n",
            "Epoch 112/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.8411 - acc: 0.6755 - val_loss: 1.0981 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.98151\n",
            "Epoch 113/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.8550 - acc: 0.6799 - val_loss: 1.0068 - val_acc: 0.6170\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.98151\n",
            "Epoch 114/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8163 - acc: 0.6896 - val_loss: 1.0134 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.98151\n",
            "Epoch 115/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.8407 - acc: 0.6804 - val_loss: 1.0315 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.98151\n",
            "Epoch 116/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8416 - acc: 0.6828 - val_loss: 1.0124 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.98151\n",
            "Epoch 117/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.8442 - acc: 0.6765 - val_loss: 1.0109 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.98151\n",
            "Epoch 118/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8386 - acc: 0.6859 - val_loss: 0.9999 - val_acc: 0.6132\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.98151\n",
            "Epoch 119/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.8112 - acc: 0.6934 - val_loss: 1.0131 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.98151\n",
            "Epoch 120/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8160 - acc: 0.6903 - val_loss: 1.0120 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.98151\n",
            "Epoch 121/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8266 - acc: 0.6864 - val_loss: 1.0212 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.98151\n",
            "Epoch 122/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.8215 - acc: 0.6879 - val_loss: 1.0108 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.98151\n",
            "Epoch 123/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.8128 - acc: 0.6929 - val_loss: 1.0309 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.98151\n",
            "Epoch 124/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.8136 - acc: 0.6883 - val_loss: 1.0242 - val_acc: 0.6161\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.98151\n",
            "Epoch 125/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.7983 - acc: 0.6980 - val_loss: 1.0047 - val_acc: 0.6074\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.98151\n",
            "Epoch 126/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.8262 - acc: 0.6927 - val_loss: 1.0216 - val_acc: 0.6257\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.98151\n",
            "Epoch 127/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.8063 - acc: 0.6937 - val_loss: 1.0293 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.98151\n",
            "Epoch 128/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.7838 - acc: 0.7048 - val_loss: 1.0268 - val_acc: 0.6161\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.98151\n",
            "Epoch 129/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.7911 - acc: 0.6995 - val_loss: 0.9987 - val_acc: 0.6248\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.98151\n",
            "Epoch 130/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.7945 - acc: 0.6990 - val_loss: 1.0289 - val_acc: 0.6132\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.98151\n",
            "Epoch 131/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.7827 - acc: 0.7000 - val_loss: 1.0128 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.98151\n",
            "Epoch 132/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7674 - acc: 0.7149 - val_loss: 0.9845 - val_acc: 0.6335\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.98151\n",
            "Epoch 133/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7845 - acc: 0.7041 - val_loss: 1.0238 - val_acc: 0.6054\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.98151\n",
            "Epoch 134/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7744 - acc: 0.7065 - val_loss: 1.0091 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.98151\n",
            "Epoch 135/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.7647 - acc: 0.7140 - val_loss: 1.0177 - val_acc: 0.6170\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.98151\n",
            "Epoch 136/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.7973 - acc: 0.6939 - val_loss: 1.0448 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.98151\n",
            "Epoch 137/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7512 - acc: 0.7169 - val_loss: 1.0364 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.98151\n",
            "Epoch 138/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.7608 - acc: 0.7149 - val_loss: 1.0115 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.98151\n",
            "Epoch 139/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.7603 - acc: 0.7053 - val_loss: 1.0136 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.98151\n",
            "Epoch 140/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.7640 - acc: 0.7178 - val_loss: 1.0092 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.98151\n",
            "Epoch 141/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.7531 - acc: 0.7108 - val_loss: 1.0325 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.98151\n",
            "Epoch 142/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.7465 - acc: 0.7336 - val_loss: 1.0334 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.98151\n",
            "Epoch 143/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.7663 - acc: 0.7084 - val_loss: 1.0127 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.98151\n",
            "Epoch 144/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.7508 - acc: 0.7145 - val_loss: 1.0089 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.98151\n",
            "Epoch 145/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.7352 - acc: 0.7258 - val_loss: 1.0240 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.98151\n",
            "Epoch 146/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.7378 - acc: 0.7239 - val_loss: 1.0025 - val_acc: 0.6199\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.98151\n",
            "Epoch 147/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.7282 - acc: 0.7186 - val_loss: 1.0410 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.98151\n",
            "Epoch 148/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.7321 - acc: 0.7147 - val_loss: 1.0744 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.98151\n",
            "Epoch 149/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.7539 - acc: 0.7203 - val_loss: 1.0365 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.98151\n",
            "Epoch 150/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.7309 - acc: 0.7169 - val_loss: 1.0146 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.98151\n",
            "Epoch 151/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.7242 - acc: 0.7278 - val_loss: 1.0501 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.98151\n",
            "Epoch 152/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7406 - acc: 0.7232 - val_loss: 1.0518 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.98151\n",
            "Epoch 153/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.7395 - acc: 0.7273 - val_loss: 1.0366 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.98151\n",
            "Epoch 154/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7196 - acc: 0.7372 - val_loss: 1.0236 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.98151\n",
            "Epoch 155/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.7145 - acc: 0.7241 - val_loss: 1.0356 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.98151\n",
            "Epoch 156/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.7188 - acc: 0.7304 - val_loss: 1.0468 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.98151\n",
            "Epoch 157/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.7260 - acc: 0.7263 - val_loss: 1.0782 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.98151\n",
            "Epoch 158/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6882 - acc: 0.7444 - val_loss: 1.0421 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.98151\n",
            "Epoch 159/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.7334 - acc: 0.7200 - val_loss: 1.0602 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.98151\n",
            "Epoch 160/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.7040 - acc: 0.7353 - val_loss: 1.0237 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.98151\n",
            "Epoch 161/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.7025 - acc: 0.7333 - val_loss: 1.0631 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.98151\n",
            "Epoch 162/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.6931 - acc: 0.7384 - val_loss: 1.0337 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.98151\n",
            "Epoch 163/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7148 - acc: 0.7326 - val_loss: 1.0648 - val_acc: 0.6161\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.98151\n",
            "Epoch 164/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.6855 - acc: 0.7490 - val_loss: 1.0360 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.98151\n",
            "Epoch 165/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.7051 - acc: 0.7372 - val_loss: 1.0660 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.98151\n",
            "Epoch 166/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.7158 - acc: 0.7287 - val_loss: 1.0513 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.98151\n",
            "Epoch 167/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.6945 - acc: 0.7362 - val_loss: 1.0576 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.98151\n",
            "Epoch 168/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.6780 - acc: 0.7461 - val_loss: 1.0409 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.98151\n",
            "Epoch 169/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6993 - acc: 0.7423 - val_loss: 1.0682 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.98151\n",
            "Epoch 170/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6929 - acc: 0.7401 - val_loss: 1.0506 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.98151\n",
            "Epoch 171/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6830 - acc: 0.7459 - val_loss: 1.0798 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.98151\n",
            "Epoch 172/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6857 - acc: 0.7377 - val_loss: 1.0453 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.98151\n",
            "Epoch 173/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6706 - acc: 0.7502 - val_loss: 1.0708 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.98151\n",
            "Epoch 174/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6764 - acc: 0.7432 - val_loss: 1.0580 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.98151\n",
            "Epoch 175/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.7047 - acc: 0.7357 - val_loss: 1.0492 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.98151\n",
            "Epoch 176/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6810 - acc: 0.7440 - val_loss: 1.0563 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.98151\n",
            "Epoch 177/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.6768 - acc: 0.7398 - val_loss: 1.0745 - val_acc: 0.6054\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.98151\n",
            "Epoch 178/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6643 - acc: 0.7556 - val_loss: 1.0455 - val_acc: 0.6074\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.98151\n",
            "Epoch 179/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6778 - acc: 0.7454 - val_loss: 1.0779 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.98151\n",
            "Epoch 180/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6778 - acc: 0.7512 - val_loss: 1.0652 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.98151\n",
            "Epoch 181/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6729 - acc: 0.7454 - val_loss: 1.0546 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.98151\n",
            "Epoch 182/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6662 - acc: 0.7471 - val_loss: 1.0766 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.98151\n",
            "Epoch 183/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6817 - acc: 0.7466 - val_loss: 1.0769 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.98151\n",
            "Epoch 184/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6666 - acc: 0.7488 - val_loss: 1.0782 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.98151\n",
            "Epoch 185/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6827 - acc: 0.7401 - val_loss: 1.0527 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.98151\n",
            "Epoch 186/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6675 - acc: 0.7437 - val_loss: 1.0540 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.98151\n",
            "Epoch 187/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6468 - acc: 0.7558 - val_loss: 1.0896 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.98151\n",
            "Epoch 188/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.6663 - acc: 0.7488 - val_loss: 1.0945 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.98151\n",
            "Epoch 189/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6625 - acc: 0.7541 - val_loss: 1.0899 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.98151\n",
            "Epoch 190/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6375 - acc: 0.7628 - val_loss: 1.0697 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.98151\n",
            "Epoch 191/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6680 - acc: 0.7510 - val_loss: 1.0603 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.98151\n",
            "Epoch 192/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6488 - acc: 0.7541 - val_loss: 1.0680 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.98151\n",
            "Epoch 193/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6514 - acc: 0.7575 - val_loss: 1.1222 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.98151\n",
            "Epoch 194/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.6598 - acc: 0.7560 - val_loss: 1.0588 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.98151\n",
            "Epoch 195/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6573 - acc: 0.7519 - val_loss: 1.0757 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.98151\n",
            "Epoch 196/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6599 - acc: 0.7464 - val_loss: 1.0881 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.98151\n",
            "Epoch 197/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.6503 - acc: 0.7500 - val_loss: 1.0424 - val_acc: 0.6112\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.98151\n",
            "Epoch 198/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6477 - acc: 0.7662 - val_loss: 1.1196 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.98151\n",
            "Epoch 199/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6573 - acc: 0.7476 - val_loss: 1.0761 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.98151\n",
            "Epoch 200/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6674 - acc: 0.7442 - val_loss: 1.0863 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.98151\n",
            "Epoch 201/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6140 - acc: 0.7693 - val_loss: 1.0885 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.98151\n",
            "Epoch 202/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6203 - acc: 0.7628 - val_loss: 1.0863 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.98151\n",
            "Epoch 203/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6370 - acc: 0.7638 - val_loss: 1.1003 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.98151\n",
            "Epoch 204/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6230 - acc: 0.7621 - val_loss: 1.1161 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.98151\n",
            "Epoch 205/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6421 - acc: 0.7589 - val_loss: 1.0837 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.98151\n",
            "Epoch 206/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.6246 - acc: 0.7618 - val_loss: 1.1234 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.98151\n",
            "Epoch 207/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6235 - acc: 0.7662 - val_loss: 1.1127 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.98151\n",
            "Epoch 208/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6270 - acc: 0.7638 - val_loss: 1.0992 - val_acc: 0.6074\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.98151\n",
            "Epoch 209/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6158 - acc: 0.7684 - val_loss: 1.0915 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.98151\n",
            "Epoch 210/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.6305 - acc: 0.7548 - val_loss: 1.1048 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.98151\n",
            "Epoch 211/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6308 - acc: 0.7589 - val_loss: 1.0765 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.98151\n",
            "Epoch 212/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.6161 - acc: 0.7735 - val_loss: 1.0762 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.98151\n",
            "Epoch 213/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6125 - acc: 0.7735 - val_loss: 1.0938 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.98151\n",
            "Epoch 214/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6327 - acc: 0.7635 - val_loss: 1.1110 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.98151\n",
            "Epoch 215/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6254 - acc: 0.7647 - val_loss: 1.0866 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.98151\n",
            "Epoch 216/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6234 - acc: 0.7730 - val_loss: 1.0725 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.98151\n",
            "Epoch 217/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6134 - acc: 0.7664 - val_loss: 1.0967 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.98151\n",
            "Epoch 218/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6005 - acc: 0.7742 - val_loss: 1.1422 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.98151\n",
            "Epoch 219/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.6134 - acc: 0.7686 - val_loss: 1.1013 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.98151\n",
            "Epoch 220/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6261 - acc: 0.7638 - val_loss: 1.1367 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.98151\n",
            "Epoch 221/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5948 - acc: 0.7725 - val_loss: 1.1193 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.98151\n",
            "Epoch 222/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.6124 - acc: 0.7735 - val_loss: 1.1259 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.98151\n",
            "Epoch 223/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5882 - acc: 0.7826 - val_loss: 1.0924 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.98151\n",
            "Epoch 224/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.6049 - acc: 0.7778 - val_loss: 1.1242 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.98151\n",
            "Epoch 225/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6225 - acc: 0.7701 - val_loss: 1.1039 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.98151\n",
            "Epoch 226/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6081 - acc: 0.7732 - val_loss: 1.1312 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.98151\n",
            "Epoch 227/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.6033 - acc: 0.7715 - val_loss: 1.1013 - val_acc: 0.6035\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.98151\n",
            "Epoch 228/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6140 - acc: 0.7689 - val_loss: 1.1106 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.98151\n",
            "Epoch 229/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5945 - acc: 0.7824 - val_loss: 1.1202 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.98151\n",
            "Epoch 230/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5906 - acc: 0.7749 - val_loss: 1.0905 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.98151\n",
            "Epoch 231/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5945 - acc: 0.7785 - val_loss: 1.1530 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 0.98151\n",
            "Epoch 232/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6143 - acc: 0.7718 - val_loss: 1.0877 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.98151\n",
            "Epoch 233/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.6235 - acc: 0.7640 - val_loss: 1.0919 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.98151\n",
            "Epoch 234/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5897 - acc: 0.7858 - val_loss: 1.1052 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.98151\n",
            "Epoch 235/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6121 - acc: 0.7633 - val_loss: 1.0915 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.98151\n",
            "Epoch 236/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5767 - acc: 0.7865 - val_loss: 1.1084 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 0.98151\n",
            "Epoch 237/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5886 - acc: 0.7807 - val_loss: 1.0972 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.98151\n",
            "Epoch 238/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5940 - acc: 0.7783 - val_loss: 1.1213 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 0.98151\n",
            "Epoch 239/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5795 - acc: 0.7855 - val_loss: 1.1469 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 0.98151\n",
            "Epoch 240/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5999 - acc: 0.7829 - val_loss: 1.1064 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 0.98151\n",
            "Epoch 241/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6222 - acc: 0.7626 - val_loss: 1.1223 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.98151\n",
            "Epoch 242/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.6144 - acc: 0.7759 - val_loss: 1.1188 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 0.98151\n",
            "Epoch 243/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5721 - acc: 0.7904 - val_loss: 1.1514 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.98151\n",
            "Epoch 244/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5719 - acc: 0.7906 - val_loss: 1.1215 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 0.98151\n",
            "Epoch 245/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5758 - acc: 0.7720 - val_loss: 1.1311 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.98151\n",
            "Epoch 246/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5802 - acc: 0.7877 - val_loss: 1.1519 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 0.98151\n",
            "Epoch 247/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5823 - acc: 0.7807 - val_loss: 1.1320 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.98151\n",
            "Epoch 248/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5943 - acc: 0.7722 - val_loss: 1.1027 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.98151\n",
            "Epoch 249/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.6046 - acc: 0.7684 - val_loss: 1.1343 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 0.98151\n",
            "Epoch 250/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.6024 - acc: 0.7764 - val_loss: 1.1213 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 0.98151\n",
            "Epoch 251/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5749 - acc: 0.7831 - val_loss: 1.0930 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 0.98151\n",
            "Epoch 252/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5707 - acc: 0.7877 - val_loss: 1.1481 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.98151\n",
            "Epoch 253/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5865 - acc: 0.7800 - val_loss: 1.1104 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.98151\n",
            "Epoch 254/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5627 - acc: 0.7901 - val_loss: 1.1554 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.98151\n",
            "Epoch 255/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.5833 - acc: 0.7814 - val_loss: 1.1190 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.98151\n",
            "Epoch 256/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5648 - acc: 0.7853 - val_loss: 1.1126 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.98151\n",
            "Epoch 257/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5610 - acc: 0.7955 - val_loss: 1.1345 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.98151\n",
            "Epoch 258/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5663 - acc: 0.7894 - val_loss: 1.1195 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.98151\n",
            "Epoch 259/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5768 - acc: 0.7843 - val_loss: 1.1056 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.98151\n",
            "Epoch 260/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5695 - acc: 0.7858 - val_loss: 1.1294 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.98151\n",
            "Epoch 261/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5406 - acc: 0.8013 - val_loss: 1.1490 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 0.98151\n",
            "Epoch 262/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5784 - acc: 0.7822 - val_loss: 1.1655 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 0.98151\n",
            "Epoch 263/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.5694 - acc: 0.7921 - val_loss: 1.1217 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.98151\n",
            "Epoch 264/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.5520 - acc: 0.7940 - val_loss: 1.1269 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.98151\n",
            "Epoch 265/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5591 - acc: 0.7843 - val_loss: 1.1285 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.98151\n",
            "Epoch 266/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5614 - acc: 0.7887 - val_loss: 1.1272 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 0.98151\n",
            "Epoch 267/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5728 - acc: 0.7812 - val_loss: 1.1010 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.98151\n",
            "Epoch 268/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5438 - acc: 0.7974 - val_loss: 1.1355 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 0.98151\n",
            "Epoch 269/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5672 - acc: 0.7921 - val_loss: 1.1030 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 0.98151\n",
            "Epoch 270/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5733 - acc: 0.7834 - val_loss: 1.1473 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.98151\n",
            "Epoch 271/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5593 - acc: 0.7887 - val_loss: 1.1017 - val_acc: 0.6054\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.98151\n",
            "Epoch 272/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5599 - acc: 0.7916 - val_loss: 1.1176 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.98151\n",
            "Epoch 273/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5672 - acc: 0.7829 - val_loss: 1.0895 - val_acc: 0.6151\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.98151\n",
            "Epoch 274/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5360 - acc: 0.7993 - val_loss: 1.1109 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.98151\n",
            "Epoch 275/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.5528 - acc: 0.7930 - val_loss: 1.1215 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.98151\n",
            "Epoch 276/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5454 - acc: 0.7986 - val_loss: 1.1131 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.98151\n",
            "Epoch 277/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5396 - acc: 0.7996 - val_loss: 1.1371 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 0.98151\n",
            "Epoch 278/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5475 - acc: 0.7962 - val_loss: 1.1030 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 0.98151\n",
            "Epoch 279/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5676 - acc: 0.7838 - val_loss: 1.1660 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 0.98151\n",
            "Epoch 280/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5545 - acc: 0.7899 - val_loss: 1.1459 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 0.98151\n",
            "Epoch 281/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5466 - acc: 0.7979 - val_loss: 1.1332 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 0.98151\n",
            "Epoch 282/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5562 - acc: 0.7909 - val_loss: 1.1163 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 0.98151\n",
            "Epoch 283/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5348 - acc: 0.8022 - val_loss: 1.1324 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 0.98151\n",
            "Epoch 284/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5456 - acc: 0.7957 - val_loss: 1.1320 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 0.98151\n",
            "Epoch 285/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5524 - acc: 0.7933 - val_loss: 1.1345 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 0.98151\n",
            "Epoch 286/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5143 - acc: 0.8022 - val_loss: 1.1161 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 0.98151\n",
            "Epoch 287/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5568 - acc: 0.7923 - val_loss: 1.1448 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 0.98151\n",
            "Epoch 288/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5609 - acc: 0.7892 - val_loss: 1.1354 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 0.98151\n",
            "Epoch 289/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5342 - acc: 0.7945 - val_loss: 1.1243 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00289: val_loss did not improve from 0.98151\n",
            "Epoch 290/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5295 - acc: 0.7969 - val_loss: 1.1419 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 0.98151\n",
            "Epoch 291/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.5369 - acc: 0.8008 - val_loss: 1.1338 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 0.98151\n",
            "Epoch 292/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5494 - acc: 0.7981 - val_loss: 1.1302 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 0.98151\n",
            "Epoch 293/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5570 - acc: 0.7945 - val_loss: 1.1631 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 0.98151\n",
            "Epoch 294/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5417 - acc: 0.8008 - val_loss: 1.1167 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 0.98151\n",
            "Epoch 295/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5429 - acc: 0.7998 - val_loss: 1.1469 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 0.98151\n",
            "Epoch 296/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5555 - acc: 0.7843 - val_loss: 1.1531 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 0.98151\n",
            "Epoch 297/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5598 - acc: 0.7892 - val_loss: 1.1408 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 0.98151\n",
            "Epoch 298/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5191 - acc: 0.8061 - val_loss: 1.1437 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 0.98151\n",
            "Epoch 299/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5383 - acc: 0.8073 - val_loss: 1.1306 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 0.98151\n",
            "Epoch 300/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5571 - acc: 0.7952 - val_loss: 1.1469 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 0.98151\n",
            "Epoch 301/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5124 - acc: 0.8117 - val_loss: 1.1528 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00301: val_loss did not improve from 0.98151\n",
            "Epoch 302/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5295 - acc: 0.8097 - val_loss: 1.1130 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 0.98151\n",
            "Epoch 303/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5349 - acc: 0.8005 - val_loss: 1.1359 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00303: val_loss did not improve from 0.98151\n",
            "Epoch 304/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5540 - acc: 0.7981 - val_loss: 1.1608 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00304: val_loss did not improve from 0.98151\n",
            "Epoch 305/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5343 - acc: 0.8059 - val_loss: 1.1607 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 0.98151\n",
            "Epoch 306/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5241 - acc: 0.8039 - val_loss: 1.1250 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 0.98151\n",
            "Epoch 307/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5234 - acc: 0.8010 - val_loss: 1.1316 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 0.98151\n",
            "Epoch 308/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5098 - acc: 0.8071 - val_loss: 1.1828 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 0.98151\n",
            "Epoch 309/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5581 - acc: 0.7913 - val_loss: 1.1604 - val_acc: 0.5986\n",
            "\n",
            "Epoch 00309: val_loss did not improve from 0.98151\n",
            "Epoch 310/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5158 - acc: 0.8083 - val_loss: 1.1617 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 0.98151\n",
            "Epoch 311/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5261 - acc: 0.8073 - val_loss: 1.1513 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 0.98151\n",
            "Epoch 312/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5198 - acc: 0.8020 - val_loss: 1.1652 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00312: val_loss did not improve from 0.98151\n",
            "Epoch 313/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5440 - acc: 0.7930 - val_loss: 1.1640 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 0.98151\n",
            "Epoch 314/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5348 - acc: 0.7988 - val_loss: 1.1476 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 0.98151\n",
            "Epoch 315/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5415 - acc: 0.8000 - val_loss: 1.1520 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 0.98151\n",
            "Epoch 316/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.5296 - acc: 0.8032 - val_loss: 1.1305 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 0.98151\n",
            "Epoch 317/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.5559 - acc: 0.7882 - val_loss: 1.1339 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 0.98151\n",
            "Epoch 318/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5310 - acc: 0.7998 - val_loss: 1.1396 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 0.98151\n",
            "Epoch 319/700\n",
            "4136/4136 [==============================] - 1s 355us/step - loss: 0.5316 - acc: 0.8029 - val_loss: 1.1543 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 0.98151\n",
            "Epoch 320/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5255 - acc: 0.8034 - val_loss: 1.1471 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 0.98151\n",
            "Epoch 321/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.5229 - acc: 0.8063 - val_loss: 1.1642 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 0.98151\n",
            "Epoch 322/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5214 - acc: 0.8075 - val_loss: 1.1507 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 0.98151\n",
            "Epoch 323/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5451 - acc: 0.7967 - val_loss: 1.1511 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 0.98151\n",
            "Epoch 324/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5173 - acc: 0.8083 - val_loss: 1.1407 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 0.98151\n",
            "Epoch 325/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5328 - acc: 0.8071 - val_loss: 1.1614 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 0.98151\n",
            "Epoch 326/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5189 - acc: 0.8097 - val_loss: 1.1420 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 0.98151\n",
            "Epoch 327/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5262 - acc: 0.8090 - val_loss: 1.1695 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 0.98151\n",
            "Epoch 328/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5126 - acc: 0.8143 - val_loss: 1.1202 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00328: val_loss did not improve from 0.98151\n",
            "Epoch 329/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5084 - acc: 0.8032 - val_loss: 1.1394 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 0.98151\n",
            "Epoch 330/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5136 - acc: 0.8088 - val_loss: 1.1448 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00330: val_loss did not improve from 0.98151\n",
            "Epoch 331/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5148 - acc: 0.8109 - val_loss: 1.1570 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 0.98151\n",
            "Epoch 332/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5242 - acc: 0.8109 - val_loss: 1.1495 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 0.98151\n",
            "Epoch 333/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5342 - acc: 0.7991 - val_loss: 1.1385 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 0.98151\n",
            "Epoch 334/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5416 - acc: 0.7952 - val_loss: 1.1270 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 0.98151\n",
            "Epoch 335/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5121 - acc: 0.8061 - val_loss: 1.1621 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 0.98151\n",
            "Epoch 336/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5161 - acc: 0.8071 - val_loss: 1.1594 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 0.98151\n",
            "Epoch 337/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5110 - acc: 0.8148 - val_loss: 1.1333 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 0.98151\n",
            "Epoch 338/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5048 - acc: 0.8160 - val_loss: 1.1477 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 0.98151\n",
            "Epoch 339/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5178 - acc: 0.8083 - val_loss: 1.1461 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 0.98151\n",
            "Epoch 340/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.5136 - acc: 0.8097 - val_loss: 1.1524 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 0.98151\n",
            "Epoch 341/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5100 - acc: 0.8102 - val_loss: 1.1426 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 0.98151\n",
            "Epoch 342/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5483 - acc: 0.7899 - val_loss: 1.1869 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 0.98151\n",
            "Epoch 343/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.5039 - acc: 0.8155 - val_loss: 1.1519 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 0.98151\n",
            "Epoch 344/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5039 - acc: 0.8150 - val_loss: 1.1584 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00344: val_loss did not improve from 0.98151\n",
            "Epoch 345/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5308 - acc: 0.8003 - val_loss: 1.1382 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 0.98151\n",
            "Epoch 346/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4885 - acc: 0.8223 - val_loss: 1.1582 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 0.98151\n",
            "Epoch 347/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5100 - acc: 0.8092 - val_loss: 1.1694 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00347: val_loss did not improve from 0.98151\n",
            "Epoch 348/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5031 - acc: 0.8075 - val_loss: 1.1603 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 0.98151\n",
            "Epoch 349/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5106 - acc: 0.8126 - val_loss: 1.1556 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 0.98151\n",
            "Epoch 350/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5189 - acc: 0.8080 - val_loss: 1.1468 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 0.98151\n",
            "Epoch 351/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.5257 - acc: 0.8068 - val_loss: 1.1551 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00351: val_loss did not improve from 0.98151\n",
            "Epoch 352/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.4700 - acc: 0.8223 - val_loss: 1.1662 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00352: val_loss did not improve from 0.98151\n",
            "Epoch 353/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5213 - acc: 0.8015 - val_loss: 1.1745 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 0.98151\n",
            "Epoch 354/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5265 - acc: 0.8010 - val_loss: 1.1721 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 0.98151\n",
            "Epoch 355/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5103 - acc: 0.8104 - val_loss: 1.1606 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 0.98151\n",
            "Epoch 356/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5093 - acc: 0.8129 - val_loss: 1.1556 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 0.98151\n",
            "Epoch 357/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4990 - acc: 0.8141 - val_loss: 1.1642 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 0.98151\n",
            "Epoch 358/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5081 - acc: 0.8102 - val_loss: 1.1866 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 0.98151\n",
            "Epoch 359/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5091 - acc: 0.8165 - val_loss: 1.1787 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00359: val_loss did not improve from 0.98151\n",
            "Epoch 360/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4746 - acc: 0.8172 - val_loss: 1.2488 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 0.98151\n",
            "Epoch 361/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.5114 - acc: 0.8066 - val_loss: 1.2165 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 0.98151\n",
            "Epoch 362/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5170 - acc: 0.8061 - val_loss: 1.1765 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 0.98151\n",
            "Epoch 363/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.5048 - acc: 0.8131 - val_loss: 1.1967 - val_acc: 0.5948\n",
            "\n",
            "Epoch 00363: val_loss did not improve from 0.98151\n",
            "Epoch 364/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5204 - acc: 0.8015 - val_loss: 1.1741 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 0.98151\n",
            "Epoch 365/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4955 - acc: 0.8170 - val_loss: 1.2028 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 0.98151\n",
            "Epoch 366/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5211 - acc: 0.8029 - val_loss: 1.1485 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 0.98151\n",
            "Epoch 367/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4827 - acc: 0.8179 - val_loss: 1.2536 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 0.98151\n",
            "Epoch 368/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5104 - acc: 0.8080 - val_loss: 1.1688 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 0.98151\n",
            "Epoch 369/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.5219 - acc: 0.8059 - val_loss: 1.1798 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 0.98151\n",
            "Epoch 370/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4988 - acc: 0.8090 - val_loss: 1.1674 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00370: val_loss did not improve from 0.98151\n",
            "Epoch 371/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4973 - acc: 0.8182 - val_loss: 1.1562 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00371: val_loss did not improve from 0.98151\n",
            "Epoch 372/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.4834 - acc: 0.8199 - val_loss: 1.1794 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 0.98151\n",
            "Epoch 373/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4872 - acc: 0.8196 - val_loss: 1.1998 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 0.98151\n",
            "Epoch 374/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4983 - acc: 0.8141 - val_loss: 1.1734 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 0.98151\n",
            "Epoch 375/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5181 - acc: 0.8083 - val_loss: 1.2112 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00375: val_loss did not improve from 0.98151\n",
            "Epoch 376/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4957 - acc: 0.8124 - val_loss: 1.1868 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 0.98151\n",
            "Epoch 377/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4914 - acc: 0.8114 - val_loss: 1.2033 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 0.98151\n",
            "Epoch 378/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5073 - acc: 0.8126 - val_loss: 1.1941 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00378: val_loss did not improve from 0.98151\n",
            "Epoch 379/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4656 - acc: 0.8271 - val_loss: 1.1589 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 0.98151\n",
            "Epoch 380/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4985 - acc: 0.8240 - val_loss: 1.1846 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 0.98151\n",
            "Epoch 381/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.5109 - acc: 0.8085 - val_loss: 1.1879 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00381: val_loss did not improve from 0.98151\n",
            "Epoch 382/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4840 - acc: 0.8286 - val_loss: 1.1655 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 0.98151\n",
            "Epoch 383/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5109 - acc: 0.8158 - val_loss: 1.1999 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00383: val_loss did not improve from 0.98151\n",
            "Epoch 384/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4675 - acc: 0.8266 - val_loss: 1.1926 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 0.98151\n",
            "Epoch 385/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5107 - acc: 0.8119 - val_loss: 1.1920 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 0.98151\n",
            "Epoch 386/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4934 - acc: 0.8216 - val_loss: 1.1788 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 0.98151\n",
            "Epoch 387/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4882 - acc: 0.8136 - val_loss: 1.1678 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 0.98151\n",
            "Epoch 388/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4780 - acc: 0.8286 - val_loss: 1.2028 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 0.98151\n",
            "Epoch 389/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4933 - acc: 0.8189 - val_loss: 1.1920 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 0.98151\n",
            "Epoch 390/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4949 - acc: 0.8158 - val_loss: 1.1712 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 0.98151\n",
            "Epoch 391/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5060 - acc: 0.8114 - val_loss: 1.2074 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 0.98151\n",
            "Epoch 392/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4973 - acc: 0.8179 - val_loss: 1.1744 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 0.98151\n",
            "Epoch 393/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4997 - acc: 0.8179 - val_loss: 1.1787 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 0.98151\n",
            "Epoch 394/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4937 - acc: 0.8119 - val_loss: 1.1993 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 0.98151\n",
            "Epoch 395/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4868 - acc: 0.8252 - val_loss: 1.1991 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 0.98151\n",
            "Epoch 396/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.4805 - acc: 0.8245 - val_loss: 1.1783 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 0.98151\n",
            "Epoch 397/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4660 - acc: 0.8317 - val_loss: 1.1803 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 0.98151\n",
            "Epoch 398/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4813 - acc: 0.8225 - val_loss: 1.1891 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 0.98151\n",
            "Epoch 399/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4864 - acc: 0.8204 - val_loss: 1.2116 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 0.98151\n",
            "Epoch 400/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.5102 - acc: 0.8158 - val_loss: 1.1812 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 0.98151\n",
            "Epoch 401/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4827 - acc: 0.8167 - val_loss: 1.2109 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00401: val_loss did not improve from 0.98151\n",
            "Epoch 402/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4872 - acc: 0.8228 - val_loss: 1.1859 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 0.98151\n",
            "Epoch 403/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4906 - acc: 0.8177 - val_loss: 1.2267 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 0.98151\n",
            "Epoch 404/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4939 - acc: 0.8201 - val_loss: 1.2182 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 0.98151\n",
            "Epoch 405/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4640 - acc: 0.8245 - val_loss: 1.2033 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 0.98151\n",
            "Epoch 406/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4903 - acc: 0.8208 - val_loss: 1.1733 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00406: val_loss did not improve from 0.98151\n",
            "Epoch 407/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4666 - acc: 0.8295 - val_loss: 1.2525 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 0.98151\n",
            "Epoch 408/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4669 - acc: 0.8279 - val_loss: 1.2837 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 0.98151\n",
            "Epoch 409/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4913 - acc: 0.8206 - val_loss: 1.2614 - val_acc: 0.5503\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 0.98151\n",
            "Epoch 410/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4806 - acc: 0.8189 - val_loss: 1.2372 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 0.98151\n",
            "Epoch 411/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.5059 - acc: 0.8131 - val_loss: 1.1987 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 0.98151\n",
            "Epoch 412/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4947 - acc: 0.8112 - val_loss: 1.1935 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 0.98151\n",
            "Epoch 413/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4958 - acc: 0.8162 - val_loss: 1.1927 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 0.98151\n",
            "Epoch 414/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4833 - acc: 0.8250 - val_loss: 1.2044 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 0.98151\n",
            "Epoch 415/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4706 - acc: 0.8276 - val_loss: 1.2061 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 0.98151\n",
            "Epoch 416/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4824 - acc: 0.8165 - val_loss: 1.1963 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 0.98151\n",
            "Epoch 417/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4562 - acc: 0.8346 - val_loss: 1.2519 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 0.98151\n",
            "Epoch 418/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4726 - acc: 0.8250 - val_loss: 1.2506 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 0.98151\n",
            "Epoch 419/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4609 - acc: 0.8308 - val_loss: 1.2412 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 0.98151\n",
            "Epoch 420/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4820 - acc: 0.8240 - val_loss: 1.2221 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 0.98151\n",
            "Epoch 421/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4775 - acc: 0.8175 - val_loss: 1.1987 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 0.98151\n",
            "Epoch 422/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4786 - acc: 0.8240 - val_loss: 1.2291 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 0.98151\n",
            "Epoch 423/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4691 - acc: 0.8269 - val_loss: 1.1969 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 0.98151\n",
            "Epoch 424/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4585 - acc: 0.8353 - val_loss: 1.2002 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 0.98151\n",
            "Epoch 425/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4801 - acc: 0.8182 - val_loss: 1.1809 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 0.98151\n",
            "Epoch 426/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4680 - acc: 0.8237 - val_loss: 1.2332 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 0.98151\n",
            "Epoch 427/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4604 - acc: 0.8266 - val_loss: 1.1957 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 0.98151\n",
            "Epoch 428/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4784 - acc: 0.8240 - val_loss: 1.2041 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 0.98151\n",
            "Epoch 429/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4775 - acc: 0.8175 - val_loss: 1.2435 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 0.98151\n",
            "Epoch 430/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4677 - acc: 0.8225 - val_loss: 1.1976 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 0.98151\n",
            "Epoch 431/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4731 - acc: 0.8204 - val_loss: 1.2495 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 0.98151\n",
            "Epoch 432/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4603 - acc: 0.8351 - val_loss: 1.2284 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 0.98151\n",
            "Epoch 433/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4626 - acc: 0.8283 - val_loss: 1.2776 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 0.98151\n",
            "Epoch 434/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4920 - acc: 0.8189 - val_loss: 1.2286 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 0.98151\n",
            "Epoch 435/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4692 - acc: 0.8257 - val_loss: 1.1924 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 0.98151\n",
            "Epoch 436/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4832 - acc: 0.8184 - val_loss: 1.2192 - val_acc: 0.5580\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 0.98151\n",
            "Epoch 437/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4786 - acc: 0.8199 - val_loss: 1.2126 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 0.98151\n",
            "Epoch 438/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4649 - acc: 0.8293 - val_loss: 1.1703 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 0.98151\n",
            "Epoch 439/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4802 - acc: 0.8184 - val_loss: 1.1992 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 0.98151\n",
            "Epoch 440/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4754 - acc: 0.8276 - val_loss: 1.2067 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 0.98151\n",
            "Epoch 441/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4753 - acc: 0.8194 - val_loss: 1.2318 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 0.98151\n",
            "Epoch 442/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.5048 - acc: 0.8095 - val_loss: 1.2203 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 0.98151\n",
            "Epoch 443/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4545 - acc: 0.8327 - val_loss: 1.2160 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 0.98151\n",
            "Epoch 444/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4803 - acc: 0.8242 - val_loss: 1.2184 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 0.98151\n",
            "Epoch 445/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4631 - acc: 0.8373 - val_loss: 1.2223 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 0.98151\n",
            "Epoch 446/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4662 - acc: 0.8300 - val_loss: 1.1943 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 0.98151\n",
            "Epoch 447/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4607 - acc: 0.8327 - val_loss: 1.2267 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 0.98151\n",
            "Epoch 448/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4867 - acc: 0.8167 - val_loss: 1.2649 - val_acc: 0.5406\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 0.98151\n",
            "Epoch 449/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4805 - acc: 0.8281 - val_loss: 1.2843 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 0.98151\n",
            "Epoch 450/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4736 - acc: 0.8250 - val_loss: 1.2183 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 0.98151\n",
            "Epoch 451/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4809 - acc: 0.8218 - val_loss: 1.2194 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 0.98151\n",
            "Epoch 452/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4735 - acc: 0.8283 - val_loss: 1.2134 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 0.98151\n",
            "Epoch 453/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4544 - acc: 0.8324 - val_loss: 1.2240 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 0.98151\n",
            "Epoch 454/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4565 - acc: 0.8317 - val_loss: 1.2364 - val_acc: 0.5580\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 0.98151\n",
            "Epoch 455/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4900 - acc: 0.8167 - val_loss: 1.2502 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 0.98151\n",
            "Epoch 456/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4700 - acc: 0.8225 - val_loss: 1.1989 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 0.98151\n",
            "Epoch 457/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4652 - acc: 0.8259 - val_loss: 1.2236 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 0.98151\n",
            "Epoch 458/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4571 - acc: 0.8235 - val_loss: 1.2188 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 0.98151\n",
            "Epoch 459/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4748 - acc: 0.8266 - val_loss: 1.2027 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 0.98151\n",
            "Epoch 460/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4834 - acc: 0.8177 - val_loss: 1.2045 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 0.98151\n",
            "Epoch 461/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4568 - acc: 0.8242 - val_loss: 1.2275 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 0.98151\n",
            "Epoch 462/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4643 - acc: 0.8259 - val_loss: 1.2170 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 0.98151\n",
            "Epoch 463/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4505 - acc: 0.8327 - val_loss: 1.2188 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 0.98151\n",
            "Epoch 464/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4593 - acc: 0.8286 - val_loss: 1.2228 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 0.98151\n",
            "Epoch 465/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4728 - acc: 0.8196 - val_loss: 1.1979 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 0.98151\n",
            "Epoch 466/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4655 - acc: 0.8305 - val_loss: 1.2228 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 0.98151\n",
            "Epoch 467/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4550 - acc: 0.8276 - val_loss: 1.2064 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 0.98151\n",
            "Epoch 468/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4683 - acc: 0.8216 - val_loss: 1.2041 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 0.98151\n",
            "Epoch 469/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4635 - acc: 0.8281 - val_loss: 1.2175 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 0.98151\n",
            "Epoch 470/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4753 - acc: 0.8177 - val_loss: 1.2263 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 0.98151\n",
            "Epoch 471/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4706 - acc: 0.8199 - val_loss: 1.1910 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 0.98151\n",
            "Epoch 472/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4790 - acc: 0.8237 - val_loss: 1.2019 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 0.98151\n",
            "Epoch 473/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4326 - acc: 0.8399 - val_loss: 1.2153 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 0.98151\n",
            "Epoch 474/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4530 - acc: 0.8298 - val_loss: 1.1811 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 0.98151\n",
            "Epoch 475/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4564 - acc: 0.8274 - val_loss: 1.1907 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 0.98151\n",
            "Epoch 476/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4517 - acc: 0.8320 - val_loss: 1.2279 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 0.98151\n",
            "Epoch 477/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4731 - acc: 0.8271 - val_loss: 1.2291 - val_acc: 0.5522\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 0.98151\n",
            "Epoch 478/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4679 - acc: 0.8247 - val_loss: 1.2041 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 0.98151\n",
            "Epoch 479/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4508 - acc: 0.8329 - val_loss: 1.2350 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 0.98151\n",
            "Epoch 480/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4576 - acc: 0.8266 - val_loss: 1.2293 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 0.98151\n",
            "Epoch 481/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4988 - acc: 0.8112 - val_loss: 1.1966 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 0.98151\n",
            "Epoch 482/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4747 - acc: 0.8223 - val_loss: 1.1930 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 0.98151\n",
            "Epoch 483/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4540 - acc: 0.8366 - val_loss: 1.2275 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 0.98151\n",
            "Epoch 484/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4632 - acc: 0.8320 - val_loss: 1.2159 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 0.98151\n",
            "Epoch 485/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4535 - acc: 0.8344 - val_loss: 1.2002 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 0.98151\n",
            "Epoch 486/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4485 - acc: 0.8356 - val_loss: 1.2501 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 0.98151\n",
            "Epoch 487/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4599 - acc: 0.8233 - val_loss: 1.2218 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 0.98151\n",
            "Epoch 488/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4671 - acc: 0.8264 - val_loss: 1.2056 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 0.98151\n",
            "Epoch 489/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4517 - acc: 0.8356 - val_loss: 1.2140 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 0.98151\n",
            "Epoch 490/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4606 - acc: 0.8310 - val_loss: 1.2544 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 0.98151\n",
            "Epoch 491/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4463 - acc: 0.8351 - val_loss: 1.2234 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 0.98151\n",
            "Epoch 492/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4506 - acc: 0.8402 - val_loss: 1.2283 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 0.98151\n",
            "Epoch 493/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4617 - acc: 0.8308 - val_loss: 1.2203 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 0.98151\n",
            "Epoch 494/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4560 - acc: 0.8322 - val_loss: 1.2327 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 0.98151\n",
            "Epoch 495/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4722 - acc: 0.8206 - val_loss: 1.2536 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 0.98151\n",
            "Epoch 496/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4372 - acc: 0.8332 - val_loss: 1.2257 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 0.98151\n",
            "Epoch 497/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4545 - acc: 0.8317 - val_loss: 1.2367 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 0.98151\n",
            "Epoch 498/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4536 - acc: 0.8288 - val_loss: 1.2424 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 0.98151\n",
            "Epoch 499/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4365 - acc: 0.8431 - val_loss: 1.2226 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 0.98151\n",
            "Epoch 500/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4513 - acc: 0.8363 - val_loss: 1.2181 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 0.98151\n",
            "Epoch 501/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4576 - acc: 0.8334 - val_loss: 1.2122 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00501: val_loss did not improve from 0.98151\n",
            "Epoch 502/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4120 - acc: 0.8515 - val_loss: 1.2074 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 0.98151\n",
            "Epoch 503/700\n",
            "4136/4136 [==============================] - 1s 341us/step - loss: 0.4636 - acc: 0.8305 - val_loss: 1.2390 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 0.98151\n",
            "Epoch 504/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4599 - acc: 0.8351 - val_loss: 1.2249 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 0.98151\n",
            "Epoch 505/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4382 - acc: 0.8368 - val_loss: 1.2221 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00505: val_loss did not improve from 0.98151\n",
            "Epoch 506/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4412 - acc: 0.8378 - val_loss: 1.2149 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 0.98151\n",
            "Epoch 507/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4643 - acc: 0.8322 - val_loss: 1.1966 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 0.98151\n",
            "Epoch 508/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4558 - acc: 0.8259 - val_loss: 1.2221 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 0.98151\n",
            "Epoch 509/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4474 - acc: 0.8327 - val_loss: 1.2330 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 0.98151\n",
            "Epoch 510/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.4742 - acc: 0.8196 - val_loss: 1.2010 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 0.98151\n",
            "Epoch 511/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4496 - acc: 0.8344 - val_loss: 1.2248 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 0.98151\n",
            "Epoch 512/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4467 - acc: 0.8341 - val_loss: 1.2135 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 0.98151\n",
            "Epoch 513/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4404 - acc: 0.8329 - val_loss: 1.1831 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 0.98151\n",
            "Epoch 514/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4490 - acc: 0.8344 - val_loss: 1.1981 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 0.98151\n",
            "Epoch 515/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4553 - acc: 0.8283 - val_loss: 1.1870 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00515: val_loss did not improve from 0.98151\n",
            "Epoch 516/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4650 - acc: 0.8300 - val_loss: 1.2309 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 0.98151\n",
            "Epoch 517/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4693 - acc: 0.8264 - val_loss: 1.2066 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 0.98151\n",
            "Epoch 518/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4332 - acc: 0.8382 - val_loss: 1.2500 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00518: val_loss did not improve from 0.98151\n",
            "Epoch 519/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4613 - acc: 0.8366 - val_loss: 1.2428 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 0.98151\n",
            "Epoch 520/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4507 - acc: 0.8344 - val_loss: 1.2118 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 0.98151\n",
            "Epoch 521/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4583 - acc: 0.8281 - val_loss: 1.1854 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 0.98151\n",
            "Epoch 522/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4545 - acc: 0.8358 - val_loss: 1.2160 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 0.98151\n",
            "Epoch 523/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4546 - acc: 0.8341 - val_loss: 1.2329 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 0.98151\n",
            "Epoch 524/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4400 - acc: 0.8368 - val_loss: 1.2208 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00524: val_loss did not improve from 0.98151\n",
            "Epoch 525/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4533 - acc: 0.8353 - val_loss: 1.2078 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00525: val_loss did not improve from 0.98151\n",
            "Epoch 526/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4381 - acc: 0.8397 - val_loss: 1.2158 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00526: val_loss did not improve from 0.98151\n",
            "Epoch 527/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4243 - acc: 0.8407 - val_loss: 1.2199 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 0.98151\n",
            "Epoch 528/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4465 - acc: 0.8363 - val_loss: 1.2170 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 0.98151\n",
            "Epoch 529/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4419 - acc: 0.8361 - val_loss: 1.2189 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 0.98151\n",
            "Epoch 530/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4555 - acc: 0.8291 - val_loss: 1.2123 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 0.98151\n",
            "Epoch 531/700\n",
            "4136/4136 [==============================] - 1s 357us/step - loss: 0.4621 - acc: 0.8233 - val_loss: 1.2038 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 0.98151\n",
            "Epoch 532/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.4390 - acc: 0.8390 - val_loss: 1.2127 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 0.98151\n",
            "Epoch 533/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4546 - acc: 0.8300 - val_loss: 1.1932 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 0.98151\n",
            "Epoch 534/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4339 - acc: 0.8426 - val_loss: 1.1899 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 0.98151\n",
            "Epoch 535/700\n",
            "4136/4136 [==============================] - 1s 355us/step - loss: 0.4420 - acc: 0.8358 - val_loss: 1.2284 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00535: val_loss did not improve from 0.98151\n",
            "Epoch 536/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4460 - acc: 0.8346 - val_loss: 1.1998 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 0.98151\n",
            "Epoch 537/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4580 - acc: 0.8334 - val_loss: 1.2321 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 0.98151\n",
            "Epoch 538/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4605 - acc: 0.8329 - val_loss: 1.1994 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 0.98151\n",
            "Epoch 539/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4342 - acc: 0.8380 - val_loss: 1.2203 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 0.98151\n",
            "Epoch 540/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4408 - acc: 0.8416 - val_loss: 1.2181 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 0.98151\n",
            "Epoch 541/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4241 - acc: 0.8450 - val_loss: 1.2311 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 0.98151\n",
            "Epoch 542/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4179 - acc: 0.8532 - val_loss: 1.2090 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00542: val_loss did not improve from 0.98151\n",
            "Epoch 543/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4475 - acc: 0.8387 - val_loss: 1.2026 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00543: val_loss did not improve from 0.98151\n",
            "Epoch 544/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4442 - acc: 0.8378 - val_loss: 1.2321 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 0.98151\n",
            "Epoch 545/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4502 - acc: 0.8295 - val_loss: 1.2415 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 0.98151\n",
            "Epoch 546/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4593 - acc: 0.8242 - val_loss: 1.2137 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 0.98151\n",
            "Epoch 547/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4417 - acc: 0.8402 - val_loss: 1.2453 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00547: val_loss did not improve from 0.98151\n",
            "Epoch 548/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4262 - acc: 0.8448 - val_loss: 1.2303 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00548: val_loss did not improve from 0.98151\n",
            "Epoch 549/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4465 - acc: 0.8320 - val_loss: 1.2420 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00549: val_loss did not improve from 0.98151\n",
            "Epoch 550/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4267 - acc: 0.8445 - val_loss: 1.2400 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 0.98151\n",
            "Epoch 551/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4370 - acc: 0.8424 - val_loss: 1.2299 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 0.98151\n",
            "Epoch 552/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4577 - acc: 0.8373 - val_loss: 1.2017 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 0.98151\n",
            "Epoch 553/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4221 - acc: 0.8470 - val_loss: 1.2243 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00553: val_loss did not improve from 0.98151\n",
            "Epoch 554/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4209 - acc: 0.8465 - val_loss: 1.2047 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 0.98151\n",
            "Epoch 555/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4355 - acc: 0.8382 - val_loss: 1.2127 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 0.98151\n",
            "Epoch 556/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4309 - acc: 0.8470 - val_loss: 1.2067 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 0.98151\n",
            "Epoch 557/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4388 - acc: 0.8419 - val_loss: 1.1921 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 0.98151\n",
            "Epoch 558/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4565 - acc: 0.8283 - val_loss: 1.2161 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 0.98151\n",
            "Epoch 559/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4369 - acc: 0.8421 - val_loss: 1.2060 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 0.98151\n",
            "Epoch 560/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4348 - acc: 0.8339 - val_loss: 1.2125 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 0.98151\n",
            "Epoch 561/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4439 - acc: 0.8358 - val_loss: 1.1812 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 0.98151\n",
            "Epoch 562/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4214 - acc: 0.8397 - val_loss: 1.2100 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 0.98151\n",
            "Epoch 563/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4433 - acc: 0.8382 - val_loss: 1.2080 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 0.98151\n",
            "Epoch 564/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4562 - acc: 0.8312 - val_loss: 1.2010 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 0.98151\n",
            "Epoch 565/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4243 - acc: 0.8431 - val_loss: 1.1766 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 0.98151\n",
            "Epoch 566/700\n",
            "4136/4136 [==============================] - 1s 354us/step - loss: 0.4106 - acc: 0.8506 - val_loss: 1.2158 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 0.98151\n",
            "Epoch 567/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4361 - acc: 0.8344 - val_loss: 1.1948 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 0.98151\n",
            "Epoch 568/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4439 - acc: 0.8346 - val_loss: 1.2061 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 0.98151\n",
            "Epoch 569/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4283 - acc: 0.8385 - val_loss: 1.2459 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 0.98151\n",
            "Epoch 570/700\n",
            "4136/4136 [==============================] - 1s 342us/step - loss: 0.4572 - acc: 0.8310 - val_loss: 1.2163 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 0.98151\n",
            "Epoch 571/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4346 - acc: 0.8438 - val_loss: 1.2499 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 0.98151\n",
            "Epoch 572/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4444 - acc: 0.8412 - val_loss: 1.2224 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 0.98151\n",
            "Epoch 573/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4375 - acc: 0.8349 - val_loss: 1.2451 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00573: val_loss did not improve from 0.98151\n",
            "Epoch 574/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4345 - acc: 0.8368 - val_loss: 1.1933 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 0.98151\n",
            "Epoch 575/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4305 - acc: 0.8397 - val_loss: 1.2858 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 0.98151\n",
            "Epoch 576/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4112 - acc: 0.8513 - val_loss: 1.2605 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 0.98151\n",
            "Epoch 577/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4448 - acc: 0.8370 - val_loss: 1.2112 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 0.98151\n",
            "Epoch 578/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4155 - acc: 0.8482 - val_loss: 1.2387 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 0.98151\n",
            "Epoch 579/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4226 - acc: 0.8457 - val_loss: 1.2086 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 0.98151\n",
            "Epoch 580/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4025 - acc: 0.8535 - val_loss: 1.2162 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 0.98151\n",
            "Epoch 581/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4365 - acc: 0.8395 - val_loss: 1.2557 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 0.98151\n",
            "Epoch 582/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4298 - acc: 0.8397 - val_loss: 1.2371 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 0.98151\n",
            "Epoch 583/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4493 - acc: 0.8395 - val_loss: 1.2512 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 0.98151\n",
            "Epoch 584/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4431 - acc: 0.8324 - val_loss: 1.2164 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 0.98151\n",
            "Epoch 585/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4380 - acc: 0.8353 - val_loss: 1.2224 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 0.98151\n",
            "Epoch 586/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4399 - acc: 0.8341 - val_loss: 1.2122 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 0.98151\n",
            "Epoch 587/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4179 - acc: 0.8457 - val_loss: 1.2179 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 0.98151\n",
            "Epoch 588/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4373 - acc: 0.8344 - val_loss: 1.2243 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 0.98151\n",
            "Epoch 589/700\n",
            "4136/4136 [==============================] - 1s 342us/step - loss: 0.4363 - acc: 0.8346 - val_loss: 1.2227 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 0.98151\n",
            "Epoch 590/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4361 - acc: 0.8457 - val_loss: 1.2255 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 0.98151\n",
            "Epoch 591/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4371 - acc: 0.8441 - val_loss: 1.2298 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 0.98151\n",
            "Epoch 592/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4306 - acc: 0.8385 - val_loss: 1.2249 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 0.98151\n",
            "Epoch 593/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4211 - acc: 0.8441 - val_loss: 1.2386 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00593: val_loss did not improve from 0.98151\n",
            "Epoch 594/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4446 - acc: 0.8349 - val_loss: 1.2496 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 0.98151\n",
            "Epoch 595/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4446 - acc: 0.8363 - val_loss: 1.2529 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 0.98151\n",
            "Epoch 596/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4439 - acc: 0.8378 - val_loss: 1.2084 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00596: val_loss did not improve from 0.98151\n",
            "Epoch 597/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4204 - acc: 0.8402 - val_loss: 1.2350 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 0.98151\n",
            "Epoch 598/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4457 - acc: 0.8349 - val_loss: 1.2065 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00598: val_loss did not improve from 0.98151\n",
            "Epoch 599/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4253 - acc: 0.8513 - val_loss: 1.2367 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 0.98151\n",
            "Epoch 600/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4021 - acc: 0.8523 - val_loss: 1.1933 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 0.98151\n",
            "Epoch 601/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4020 - acc: 0.8503 - val_loss: 1.2334 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 0.98151\n",
            "Epoch 602/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4241 - acc: 0.8445 - val_loss: 1.2109 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 0.98151\n",
            "Epoch 603/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4179 - acc: 0.8457 - val_loss: 1.2436 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 0.98151\n",
            "Epoch 604/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4258 - acc: 0.8431 - val_loss: 1.2028 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00604: val_loss did not improve from 0.98151\n",
            "Epoch 605/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4338 - acc: 0.8395 - val_loss: 1.2033 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00605: val_loss did not improve from 0.98151\n",
            "Epoch 606/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4137 - acc: 0.8520 - val_loss: 1.2444 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00606: val_loss did not improve from 0.98151\n",
            "Epoch 607/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4281 - acc: 0.8443 - val_loss: 1.2176 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00607: val_loss did not improve from 0.98151\n",
            "Epoch 608/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4195 - acc: 0.8474 - val_loss: 1.2298 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 0.98151\n",
            "Epoch 609/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4356 - acc: 0.8407 - val_loss: 1.2454 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00609: val_loss did not improve from 0.98151\n",
            "Epoch 610/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4217 - acc: 0.8426 - val_loss: 1.2219 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 0.98151\n",
            "Epoch 611/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4139 - acc: 0.8537 - val_loss: 1.2303 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00611: val_loss did not improve from 0.98151\n",
            "Epoch 612/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4111 - acc: 0.8486 - val_loss: 1.2100 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00612: val_loss did not improve from 0.98151\n",
            "Epoch 613/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4231 - acc: 0.8472 - val_loss: 1.2509 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00613: val_loss did not improve from 0.98151\n",
            "Epoch 614/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4102 - acc: 0.8460 - val_loss: 1.2205 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00614: val_loss did not improve from 0.98151\n",
            "Epoch 615/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4241 - acc: 0.8407 - val_loss: 1.2366 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00615: val_loss did not improve from 0.98151\n",
            "Epoch 616/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4429 - acc: 0.8346 - val_loss: 1.2273 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00616: val_loss did not improve from 0.98151\n",
            "Epoch 617/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.3887 - acc: 0.8542 - val_loss: 1.2606 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00617: val_loss did not improve from 0.98151\n",
            "Epoch 618/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4268 - acc: 0.8397 - val_loss: 1.2571 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00618: val_loss did not improve from 0.98151\n",
            "Epoch 619/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4006 - acc: 0.8586 - val_loss: 1.2372 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00619: val_loss did not improve from 0.98151\n",
            "Epoch 620/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4322 - acc: 0.8426 - val_loss: 1.2689 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00620: val_loss did not improve from 0.98151\n",
            "Epoch 621/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4329 - acc: 0.8409 - val_loss: 1.2335 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 0.98151\n",
            "Epoch 622/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4155 - acc: 0.8421 - val_loss: 1.2567 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 0.98151\n",
            "Epoch 623/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4480 - acc: 0.8356 - val_loss: 1.2260 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 0.98151\n",
            "Epoch 624/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4111 - acc: 0.8433 - val_loss: 1.2536 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 0.98151\n",
            "Epoch 625/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4128 - acc: 0.8428 - val_loss: 1.2248 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00625: val_loss did not improve from 0.98151\n",
            "Epoch 626/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4138 - acc: 0.8412 - val_loss: 1.2375 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00626: val_loss did not improve from 0.98151\n",
            "Epoch 627/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4083 - acc: 0.8477 - val_loss: 1.2874 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00627: val_loss did not improve from 0.98151\n",
            "Epoch 628/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4221 - acc: 0.8467 - val_loss: 1.2542 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00628: val_loss did not improve from 0.98151\n",
            "Epoch 629/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4194 - acc: 0.8470 - val_loss: 1.2622 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00629: val_loss did not improve from 0.98151\n",
            "Epoch 630/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4422 - acc: 0.8305 - val_loss: 1.2404 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00630: val_loss did not improve from 0.98151\n",
            "Epoch 631/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4398 - acc: 0.8399 - val_loss: 1.2211 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 0.98151\n",
            "Epoch 632/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4216 - acc: 0.8397 - val_loss: 1.2443 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 0.98151\n",
            "Epoch 633/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4191 - acc: 0.8412 - val_loss: 1.2701 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00633: val_loss did not improve from 0.98151\n",
            "Epoch 634/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4519 - acc: 0.8373 - val_loss: 1.2248 - val_acc: 0.5909\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 0.98151\n",
            "Epoch 635/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4197 - acc: 0.8460 - val_loss: 1.2501 - val_acc: 0.5812\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 0.98151\n",
            "Epoch 636/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4064 - acc: 0.8499 - val_loss: 1.2146 - val_acc: 0.5822\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 0.98151\n",
            "Epoch 637/700\n",
            "4136/4136 [==============================] - 1s 342us/step - loss: 0.4167 - acc: 0.8499 - val_loss: 1.2481 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 0.98151\n",
            "Epoch 638/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4188 - acc: 0.8448 - val_loss: 1.2598 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00638: val_loss did not improve from 0.98151\n",
            "Epoch 639/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4294 - acc: 0.8390 - val_loss: 1.2297 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00639: val_loss did not improve from 0.98151\n",
            "Epoch 640/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4145 - acc: 0.8503 - val_loss: 1.2404 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00640: val_loss did not improve from 0.98151\n",
            "Epoch 641/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4153 - acc: 0.8494 - val_loss: 1.2484 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00641: val_loss did not improve from 0.98151\n",
            "Epoch 642/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4152 - acc: 0.8508 - val_loss: 1.2723 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00642: val_loss did not improve from 0.98151\n",
            "Epoch 643/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4098 - acc: 0.8482 - val_loss: 1.2561 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 0.98151\n",
            "Epoch 644/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4158 - acc: 0.8486 - val_loss: 1.2438 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00644: val_loss did not improve from 0.98151\n",
            "Epoch 645/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4211 - acc: 0.8501 - val_loss: 1.2604 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00645: val_loss did not improve from 0.98151\n",
            "Epoch 646/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4289 - acc: 0.8426 - val_loss: 1.2165 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00646: val_loss did not improve from 0.98151\n",
            "Epoch 647/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.3973 - acc: 0.8542 - val_loss: 1.2776 - val_acc: 0.5774\n",
            "\n",
            "Epoch 00647: val_loss did not improve from 0.98151\n",
            "Epoch 648/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4152 - acc: 0.8472 - val_loss: 1.2642 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00648: val_loss did not improve from 0.98151\n",
            "Epoch 649/700\n",
            "4136/4136 [==============================] - 1s 343us/step - loss: 0.4328 - acc: 0.8402 - val_loss: 1.2664 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00649: val_loss did not improve from 0.98151\n",
            "Epoch 650/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4133 - acc: 0.8472 - val_loss: 1.2488 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 0.98151\n",
            "Epoch 651/700\n",
            "4136/4136 [==============================] - 1s 341us/step - loss: 0.4163 - acc: 0.8445 - val_loss: 1.2928 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00651: val_loss did not improve from 0.98151\n",
            "Epoch 652/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4118 - acc: 0.8477 - val_loss: 1.2700 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 0.98151\n",
            "Epoch 653/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4144 - acc: 0.8496 - val_loss: 1.2565 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 0.98151\n",
            "Epoch 654/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4126 - acc: 0.8477 - val_loss: 1.2662 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00654: val_loss did not improve from 0.98151\n",
            "Epoch 655/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4024 - acc: 0.8532 - val_loss: 1.2545 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00655: val_loss did not improve from 0.98151\n",
            "Epoch 656/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4229 - acc: 0.8532 - val_loss: 1.3036 - val_acc: 0.5658\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 0.98151\n",
            "Epoch 657/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4138 - acc: 0.8484 - val_loss: 1.2682 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 0.98151\n",
            "Epoch 658/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4093 - acc: 0.8484 - val_loss: 1.2477 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00658: val_loss did not improve from 0.98151\n",
            "Epoch 659/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4002 - acc: 0.8528 - val_loss: 1.2579 - val_acc: 0.5851\n",
            "\n",
            "Epoch 00659: val_loss did not improve from 0.98151\n",
            "Epoch 660/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4211 - acc: 0.8494 - val_loss: 1.2436 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00660: val_loss did not improve from 0.98151\n",
            "Epoch 661/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4341 - acc: 0.8402 - val_loss: 1.2310 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00661: val_loss did not improve from 0.98151\n",
            "Epoch 662/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4088 - acc: 0.8445 - val_loss: 1.2928 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00662: val_loss did not improve from 0.98151\n",
            "Epoch 663/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4145 - acc: 0.8460 - val_loss: 1.2689 - val_acc: 0.5793\n",
            "\n",
            "Epoch 00663: val_loss did not improve from 0.98151\n",
            "Epoch 664/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4178 - acc: 0.8431 - val_loss: 1.2403 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00664: val_loss did not improve from 0.98151\n",
            "Epoch 665/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4309 - acc: 0.8395 - val_loss: 1.2708 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00665: val_loss did not improve from 0.98151\n",
            "Epoch 666/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4262 - acc: 0.8378 - val_loss: 1.2215 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 0.98151\n",
            "Epoch 667/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4260 - acc: 0.8460 - val_loss: 1.2574 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 0.98151\n",
            "Epoch 668/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.4145 - acc: 0.8515 - val_loss: 1.2426 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 0.98151\n",
            "Epoch 669/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4087 - acc: 0.8441 - val_loss: 1.2376 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 0.98151\n",
            "Epoch 670/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4102 - acc: 0.8523 - val_loss: 1.2437 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 0.98151\n",
            "Epoch 671/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4138 - acc: 0.8491 - val_loss: 1.2915 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 0.98151\n",
            "Epoch 672/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4264 - acc: 0.8392 - val_loss: 1.2219 - val_acc: 0.5870\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 0.98151\n",
            "Epoch 673/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4221 - acc: 0.8433 - val_loss: 1.2408 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00673: val_loss did not improve from 0.98151\n",
            "Epoch 674/700\n",
            "4136/4136 [==============================] - 1s 342us/step - loss: 0.3952 - acc: 0.8520 - val_loss: 1.2380 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00674: val_loss did not improve from 0.98151\n",
            "Epoch 675/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4099 - acc: 0.8501 - val_loss: 1.2915 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00675: val_loss did not improve from 0.98151\n",
            "Epoch 676/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4038 - acc: 0.8549 - val_loss: 1.2547 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00676: val_loss did not improve from 0.98151\n",
            "Epoch 677/700\n",
            "4136/4136 [==============================] - 1s 351us/step - loss: 0.4035 - acc: 0.8470 - val_loss: 1.2461 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00677: val_loss did not improve from 0.98151\n",
            "Epoch 678/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4099 - acc: 0.8494 - val_loss: 1.2687 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00678: val_loss did not improve from 0.98151\n",
            "Epoch 679/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4137 - acc: 0.8494 - val_loss: 1.2530 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00679: val_loss did not improve from 0.98151\n",
            "Epoch 680/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4030 - acc: 0.8515 - val_loss: 1.2724 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00680: val_loss did not improve from 0.98151\n",
            "Epoch 681/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4045 - acc: 0.8554 - val_loss: 1.2949 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00681: val_loss did not improve from 0.98151\n",
            "Epoch 682/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4229 - acc: 0.8448 - val_loss: 1.2303 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 0.98151\n",
            "Epoch 683/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.3917 - acc: 0.8600 - val_loss: 1.3042 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 0.98151\n",
            "Epoch 684/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4188 - acc: 0.8482 - val_loss: 1.2495 - val_acc: 0.5764\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 0.98151\n",
            "Epoch 685/700\n",
            "4136/4136 [==============================] - 1s 352us/step - loss: 0.4212 - acc: 0.8438 - val_loss: 1.2291 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00685: val_loss did not improve from 0.98151\n",
            "Epoch 686/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.4215 - acc: 0.8426 - val_loss: 1.2994 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00686: val_loss did not improve from 0.98151\n",
            "Epoch 687/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4151 - acc: 0.8445 - val_loss: 1.2772 - val_acc: 0.5648\n",
            "\n",
            "Epoch 00687: val_loss did not improve from 0.98151\n",
            "Epoch 688/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.3819 - acc: 0.8586 - val_loss: 1.2617 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00688: val_loss did not improve from 0.98151\n",
            "Epoch 689/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.4439 - acc: 0.8414 - val_loss: 1.2455 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 0.98151\n",
            "Epoch 690/700\n",
            "4136/4136 [==============================] - 1s 347us/step - loss: 0.4148 - acc: 0.8433 - val_loss: 1.3039 - val_acc: 0.5590\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 0.98151\n",
            "Epoch 691/700\n",
            "4136/4136 [==============================] - 1s 344us/step - loss: 0.3897 - acc: 0.8566 - val_loss: 1.2667 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 0.98151\n",
            "Epoch 692/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.4305 - acc: 0.8378 - val_loss: 1.2412 - val_acc: 0.5899\n",
            "\n",
            "Epoch 00692: val_loss did not improve from 0.98151\n",
            "Epoch 693/700\n",
            "4136/4136 [==============================] - 1s 349us/step - loss: 0.3993 - acc: 0.8532 - val_loss: 1.2369 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 0.98151\n",
            "Epoch 694/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4347 - acc: 0.8341 - val_loss: 1.2293 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 0.98151\n",
            "Epoch 695/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.4200 - acc: 0.8467 - val_loss: 1.2547 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00695: val_loss did not improve from 0.98151\n",
            "Epoch 696/700\n",
            "4136/4136 [==============================] - 1s 345us/step - loss: 0.3883 - acc: 0.8617 - val_loss: 1.2765 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00696: val_loss did not improve from 0.98151\n",
            "Epoch 697/700\n",
            "4136/4136 [==============================] - 1s 353us/step - loss: 0.4054 - acc: 0.8457 - val_loss: 1.2597 - val_acc: 0.5696\n",
            "\n",
            "Epoch 00697: val_loss did not improve from 0.98151\n",
            "Epoch 698/700\n",
            "4136/4136 [==============================] - 1s 348us/step - loss: 0.3868 - acc: 0.8540 - val_loss: 1.2809 - val_acc: 0.5725\n",
            "\n",
            "Epoch 00698: val_loss did not improve from 0.98151\n",
            "Epoch 699/700\n",
            "4136/4136 [==============================] - 1s 350us/step - loss: 0.4190 - acc: 0.8499 - val_loss: 1.2694 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00699: val_loss did not improve from 0.98151\n",
            "Epoch 700/700\n",
            "4136/4136 [==============================] - 1s 346us/step - loss: 0.4006 - acc: 0.8544 - val_loss: 1.2731 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00700: val_loss did not improve from 0.98151\n",
            "Training completed in time:  0:16:53.128138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlBMfac6TXnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}